{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f457df4-a840-4838-9b30-fc5feb2c09b5",
   "metadata": {},
   "source": [
    "# Assignment 3: Neural networks in natural language processing\n",
    "\n",
    "### Due Date: Oct 30 (both sections)\n",
    "\n",
    "### Grade (100 pts, 10%)\n",
    "\n",
    "#### Your Name:\n",
    "\n",
    "#### Your EID:\n",
    "\n",
    "*Note: This assignment covers material from the recording, notes, demo, and suggested readings from Lecture-08*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name : Haoyu Wang\n",
    "EID : hw468"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040c21a-f813-4ce5-b5d7-bbdd59e37dcc",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369615c-54d7-4a72-bfe2-6fd84cef9582",
   "metadata": {},
   "source": [
    "### 1. Dropout (50 pts)\n",
    "\n",
    "Dropout is a regularization technique that randomly sets units in each activation layer, $a \\in \\mathbb{R}^{D}$, to zero and then multiplies the resultant vector elementwise by a constant $\\gamma$ according to:\n",
    "\n",
    "$$a_{dropout} \\leftarrow  \\gamma H \\odot a$$\n",
    "\n",
    "where $\\odot$ represents the element-wise product operator and $H \\in \\{0, 1\\}^D$ is a mask with entries drawn from \n",
    "\n",
    "$$\\begin{cases} p(0) &= p_{dropout} \\\\ p(1) &= 1 - p_{dropout} \\end{cases}$$\n",
    "\n",
    "Select a scaling factor ${\\gamma}$ that ensures the expected value over the activation layer remains invariant to the above operation, $E\\big[ a_{dropout} \\big] = E\\big[ a \\big]$, and provide rationale for your selection.\n",
    "\n",
    "*Hint: You want to show that*\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^D a_i = \\gamma \\sum_{i=1}^D a_{dropout, i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d08cbe0-e13b-4325-a3b8-363c78a5fdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create the original 10000 array with all values are 1\n",
    "A=np.ones((10000))\n",
    "np.mean(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9e7dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 0]\n",
      "[0. 1. 1. ... 0. 1. 0.]\n",
      "B= [0.         1.66666667 1.66666667 ... 0.         1.66666667 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9979999999999998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropout function\n",
    "def dropout(x, level):\n",
    "    if level < 0. or level >= 1: \n",
    "        raise ValueError('Dropout level must be in interval [0, 1[.')\n",
    "    prob = 1. - level\n",
    "    \n",
    "    #Create a tensor with Bernoulli distribution with p=0.4\n",
    "    random_tensor = np.random.binomial(n=1, p=prob, size=x.shape) \n",
    "    print(random_tensor)\n",
    "    #Dropout \n",
    "    x *= random_tensor\n",
    "    print(x)\n",
    "    #Rescale\n",
    "    x /= prob\n",
    "\n",
    "    return x\n",
    "\n",
    "#Dropout A with 0.4 probability \n",
    "B=dropout(A,0.4)\n",
    "print(\"B=\",B)\n",
    "np.mean(B)\n",
    "##From the process above, we can easily find that ‚àëùëñ=1ùê∑ùëéùëñ=ùõæ‚àëùëñ=1ùê∑ùëéùëëùëüùëúùëùùëúùë¢ùë°,ùëñ almostly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2785529-1d06-4474-8aec-baef38545787",
   "metadata": {},
   "source": [
    "### 2. Convolutions (50 pts)\n",
    "\n",
    "Consider a sequence of $T$ token embeddings, $Z \\in \\mathbb{R}^{T \\times D}$, for which $D=3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347fcde5-c66a-4b4d-a7de-8491b5fcc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Z = np.array([\n",
    "    [1.3,   0.4, -0.2],\n",
    "    [-3.1,  1.1,  2.1],\n",
    "    [0.9,   2.8, -1.5],\n",
    "    [1.3,   2.4,  0.1],\n",
    "    [1.0,   1.0,  0.5],\n",
    "    [3.0,  -1.4, -0.2],\n",
    "    [-0.7,  1.8,  1.3]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3cbe3-5b3a-44aa-886f-9f56e126e04d",
   "metadata": {},
   "source": [
    "and a set of convolutional filters, $W=\\{ w^{(1)}, w^{(2)} \\}$, and corresponding filter widths $S=\\{ s^{(1)}, s^{(2)}  \\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "437d0a4d-57ea-42c9-97d1-60055b3fbfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 1, 1],\n",
      "       [1, 1, 1]]), array([[2, 2, 2],\n",
      "       [2, 2, 2],\n",
      "       [2, 2, 2]])]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "w2 = np.array([\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2]\n",
    "])\n",
    "\n",
    "W = [w1, w2]\n",
    "print(W)\n",
    "S = [2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c6909-6c25-4dde-8a87-fa79b27dbf3e",
   "metadata": {},
   "source": [
    "In Lecture 08 we discussed a set of operations that maps $Z \\in \\mathbb{R}^{T \\times D}$ onto $Z' \\in \\mathbb{R}^{N_F D}$ (in this problem $N_F = 2$). This involved three steps:\n",
    "\n",
    "1. **Convolution**: The convolutional operation produces $N_F$ feature maps, $B^{(n)} \\in \\mathbb{R}^{(T - s^{(n)} + 1) \\times D}$, where $n=\\{1, \\dots, N_F\\}$, according to:\n",
    "\n",
    "$$\n",
    "\\forall_{t \\in \\{ 1, \\dots, T - s^{(n)} + 1 \\} } \\; B^{(n)}_{t,j} = \\sum_{t'=1}^{S^{(n)}} w^{(n)}_{t',j} \\; Z_{t,j}\n",
    "$$\n",
    "\n",
    "2. **Max pooling**: The max pooling operation computes the max over the sequence dimension in each feature map, $ B_{maxpool}^{(n)} \\in \\mathbb{R}^D$, according to:\n",
    "\n",
    "$$\n",
    "B_{maxpool, j}^{(n)} = \\underset{1 \\leq t' \\leq T - s^{(n)} + 1 }{\\max} B^{(n)}_{t', j}\n",
    "$$\n",
    "\n",
    "3. **Concatenation**: The resultant set of $N_F$ feature vectors are then concatenated into a single vector $Z'$ according to:\n",
    "\n",
    "$$\n",
    "Z' = \\big[ B_{maxpool}^{(1)}, \\dots, B_{maxpool}^{(n)}, \\dots,  B_{maxpool}^{(N_F)}  \\big] \\in \\mathbb{R}^{D \\cdot N_F}\n",
    "$$\n",
    "\n",
    "In the cell below, perform these three operations to produce $Z' \\in \\mathbb{R}^6$ and print it.\n",
    "\n",
    "*Hint: The max pooling operation computes the maximum over each column in $B^{(n)}$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da7747a3-da78-44e9-ae19-c3f464bd9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########Convolution process\n",
    "import numpy as np\n",
    "t,d=Z.shape\n",
    "print(t,d)\n",
    "S[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "834263ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.6],\n",
      "       [2.3],\n",
      "       [6. ],\n",
      "       [6.3],\n",
      "       [3.9],\n",
      "       [3.8]]), array([[ 7.6],\n",
      "       [12.2],\n",
      "       [17. ],\n",
      "       [15.4],\n",
      "       [12.6]])]\n"
     ]
    }
   ],
   "source": [
    "#1.Convolution\n",
    "def convolution(w,Z,n):\n",
    "    t,d=Z.shape\n",
    "    conv=[]\n",
    "    for i in range(t-S[n]+1):\n",
    "        row = []\n",
    "        for j in range (1):\n",
    "            a=Z[i:i+S[n],j:j+d]\n",
    "            row.append(np.sum(np.multiply(w,a)))\n",
    "        conv.append(row)\n",
    "    return np.array(conv)\n",
    "\n",
    "c1=convolution(w1,Z,0)\n",
    "c2=convolution(w2,Z,1)\n",
    "C=[c1,c2]\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7068d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Max pooling\n",
    "def Max_pooling(C):\n",
    "    t,d=Z.shape\n",
    "    pool=[]\n",
    "    for i in range (2):\n",
    "        row=[]\n",
    "        row.append(np.max(C[i]))\n",
    "        pool.append(row)\n",
    "    return np.array(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e00a8265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.3]\n",
      " [17. ]]\n"
     ]
    }
   ],
   "source": [
    "MP=Max_pooling(C)\n",
    "print(MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7df4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Concatenation\n",
    "type(MP)\n",
    "def concatenation (Max_pooling):\n",
    "    Z_concate=np.reshape(Max_pooling,-1)\n",
    "    return Z_concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "602bec81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.3, 17. ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenation(MP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
