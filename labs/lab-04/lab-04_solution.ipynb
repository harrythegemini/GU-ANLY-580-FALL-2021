{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2640818d-560f-4bda-b8c5-dd75ebbe1ec8",
   "metadata": {},
   "source": [
    "# Lab 04: Extracting topics from research articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eaeccb-cf1f-47e1-8dfb-06ac139bd64d",
   "metadata": {},
   "source": [
    "# Part I: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984fd692-eeb5-4dfa-b64b-05fd32b5a1c6",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "- Source: https://www.kaggle.com/blessondensil294/topic-modeling-for-research-articles/version/1\n",
    "- Download: https://georgetown.box.com/s/1qkrvdewe8ez35f2asblxysh136dvh6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec830e7-b20d-469b-a552-34d6f4f8cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('research-articles-dataset/train.csv').sample(frac=1)\n",
    "test_data = pd.read_csv('research-articles-dataset/test.csv').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d122fd-be0d-411d-bd06-376cec211ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1055</td>\n",
       "      <td>Emergent electronic structure of CaFe2As2</td>\n",
       "      <td>CaFe2As2 exhibits collapsed tetragonal (cT) ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>1077</td>\n",
       "      <td>Evidence for a radiatively driven disc-wind in...</td>\n",
       "      <td>We present a newly discovered correlation be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17492</th>\n",
       "      <td>17493</td>\n",
       "      <td>Anomalous slowing down of individual human act...</td>\n",
       "      <td>Motivated by a host of empirical evidences r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>8920</td>\n",
       "      <td>Model order reduction for random nonlinear dyn...</td>\n",
       "      <td>We examine nonlinear dynamical systems of or...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13966</th>\n",
       "      <td>13967</td>\n",
       "      <td>Combined MEG and fMRI Exponential Random Graph...</td>\n",
       "      <td>Estimated connectomes by the means of neuroi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>4644</td>\n",
       "      <td>Evolutionary Generative Adversarial Networks</td>\n",
       "      <td>Generative adversarial networks (GAN) have b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <td>11588</td>\n",
       "      <td>Network support of talented people</td>\n",
       "      <td>Network support is a key success factor for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>699</td>\n",
       "      <td>A Comparative Analysis of Contact Models in Tr...</td>\n",
       "      <td>In this paper, we analyze the effects of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>14291</td>\n",
       "      <td>Dimer correlation amplitudes and dimer excitat...</td>\n",
       "      <td>Correlation functions of dimer operators, th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13943</th>\n",
       "      <td>13944</td>\n",
       "      <td>Finiteness theorems for K3 surfaces and abelia...</td>\n",
       "      <td>We study abelian varieties and K3 surfaces w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20972 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TITLE  \\\n",
       "1054    1055          Emergent electronic structure of CaFe2As2   \n",
       "1076    1077  Evidence for a radiatively driven disc-wind in...   \n",
       "17492  17493  Anomalous slowing down of individual human act...   \n",
       "8919    8920  Model order reduction for random nonlinear dyn...   \n",
       "13966  13967  Combined MEG and fMRI Exponential Random Graph...   \n",
       "...      ...                                                ...   \n",
       "4643    4644       Evolutionary Generative Adversarial Networks   \n",
       "11587  11588                 Network support of talented people   \n",
       "698      699  A Comparative Analysis of Contact Models in Tr...   \n",
       "14290  14291  Dimer correlation amplitudes and dimer excitat...   \n",
       "13943  13944  Finiteness theorems for K3 surfaces and abelia...   \n",
       "\n",
       "                                                ABSTRACT  Computer Science  \\\n",
       "1054     CaFe2As2 exhibits collapsed tetragonal (cT) ...                 0   \n",
       "1076     We present a newly discovered correlation be...                 0   \n",
       "17492    Motivated by a host of empirical evidences r...                 0   \n",
       "8919     We examine nonlinear dynamical systems of or...                 0   \n",
       "13966    Estimated connectomes by the means of neuroi...                 0   \n",
       "...                                                  ...               ...   \n",
       "4643     Generative adversarial networks (GAN) have b...                 0   \n",
       "11587    Network support is a key success factor for ...                 1   \n",
       "698      In this paper, we analyze the effects of con...                 1   \n",
       "14290    Correlation functions of dimer operators, th...                 0   \n",
       "13943    We study abelian varieties and K3 surfaces w...                 0   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "1054         1            0           0                     0   \n",
       "1076         1            0           0                     0   \n",
       "17492        1            0           0                     0   \n",
       "8919         0            1           0                     0   \n",
       "13966        0            0           0                     1   \n",
       "...        ...          ...         ...                   ...   \n",
       "4643         0            0           1                     0   \n",
       "11587        1            0           0                     0   \n",
       "698          0            0           0                     0   \n",
       "14290        1            0           0                     0   \n",
       "13943        0            1           0                     0   \n",
       "\n",
       "       Quantitative Finance  \n",
       "1054                      0  \n",
       "1076                      0  \n",
       "17492                     0  \n",
       "8919                      0  \n",
       "13966                     0  \n",
       "...                     ...  \n",
       "4643                      0  \n",
       "11587                     0  \n",
       "698                       0  \n",
       "14290                     0  \n",
       "13943                     0  \n",
       "\n",
       "[20972 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fda973-f99a-479d-bd36-412183d3e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Science: 0.410\n",
      "Physics: 0.287\n",
      "Mathematics: 0.268\n",
      "Statistics: 0.248\n",
      "Quantitative Biology: 0.028\n",
      "Quantitative Finance: 0.012\n"
     ]
    }
   ],
   "source": [
    "for topic in train_data.columns[3:]:\n",
    "    print(f\"{topic}: {sum(train_data[topic]) / len(train_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c93ce6-0986-4b37-b7c6-14caf6002c6e",
   "metadata": {},
   "source": [
    "### Reuse Spacy pipeline from Lab-02 for text normalization & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0a87b5-e8d5-4968-b065-bccb27479b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.ng20_preprocess(doc)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "M = 2500\n",
    "\n",
    "pipeline = spacy.load('en_core_web_sm')\n",
    "\n",
    "# http://emailregex.com/\n",
    "email_re = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "\n",
    "# replace = [ (pattern-to-replace, replacement),  ...]\n",
    "replace = [\n",
    "    (r\"<a[^>]*>(.*?)</a>\", r\"\\1\"),  # Matches most URLs\n",
    "    (email_re, \"email\"),            # Matches emails\n",
    "    (r\"(?<=\\d),(?=\\d)\", \"\"),        # Remove commas in numbers\n",
    "    (r\"\\d+\", \"number\"),              # Map digits to special token <numbr>\n",
    "    (r\"[\\t\\n\\r\\*\\.\\@\\,\\-\\/]\", \" \"), # Punctuation and other junk\n",
    "    (r\"\\s+\", \" \")                   # Stips extra whitespace\n",
    "]\n",
    "\n",
    "train_sentences = []\n",
    "for i, d in enumerate(train_data['ABSTRACT'][:M]):\n",
    "    for repl in replace:\n",
    "        d = re.sub(repl[0], repl[1], d)\n",
    "    train_sentences.append(d)\n",
    "\n",
    "\n",
    "@Language.component(\"lab04Preprocessor\")\n",
    "def ng20_preprocess(doc):\n",
    "    tokens = [token for token in doc \n",
    "              if not any((token.is_stop, token.is_punct))]\n",
    "    tokens = [token.lemma_.lower().strip() for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "pipeline.add_pipe(\"lab04Preprocessor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c19c8-80ec-4bb2-a7bd-aaad024d4e7b",
   "metadata": {},
   "source": [
    "### Pass data through our Spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b68ad3-f1a4-4f2a-b3a5-7f9fc0456ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for sent in train_sentences[:M]:\n",
    "    docs.append(pipeline(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36b399-6417-4c64-a28f-b9ace7cc4a16",
   "metadata": {},
   "source": [
    "### Compute number of unique words (vocabulary size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f21867e-25ef-4118-8e64-7abc6fb24b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16894"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(set(\" \".join(docs).split(\" \")))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9064a1-c13c-4510-b5be-fc8b6a37c6a6",
   "metadata": {},
   "source": [
    "# Part 2: Build Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97d061-e99f-4675-9c3a-7fa65350384e",
   "metadata": {},
   "source": [
    "### Build the term-document matrix (i.e., BOW features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c95cfcc-ef76-4465-8ff2-d17bd12f9101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (2500, 1988))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "bow_featurizer = CountVectorizer(max_features=vocab_size, max_df=0.95, min_df=0.005, stop_words='english')\n",
    "tfidf_featurizer = TfidfVectorizer(max_features=vocab_size, max_df=0.95, stop_words='english')\n",
    "X_bow = bow_featurizer.fit_transform(docs)\n",
    "X_tfidf = tfidf_featurizer.fit_transform(docs)\n",
    "type(X_bow), X_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b30a34-698f-46bf-bc50-890a0dd50a1f",
   "metadata": {},
   "source": [
    "### Create a index-to-word map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f86bd6c-8a0a-4c9c-bd51-2896ec3fb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: word for word, idx in bow_featurizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf9c1a-46eb-488e-a734-d35381c5d7ca",
   "metadata": {},
   "source": [
    "### Number of topics hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f32a2ed-9ab2-4103-806b-90d4e3a57152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e7176-a6b0-48f1-99ca-2d49cf186862",
   "metadata": {},
   "source": [
    "### Plotting subroutine to visualize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b1c81d-0b21-47f9-8a35-61d435e8dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    plt.clf()\n",
    "    cols = 5\n",
    "    rows = K // 5 + K % 5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[::-1][:n_top_words]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f'Topic {topic_idx + 1}',\n",
    "                     fontdict={'fontsize': 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        for i in 'top right left'.split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be137c12-6647-40c9-8566-61f3ba0001a1",
   "metadata": {},
   "source": [
    "### (10 pts) Task I: Build a LSA model\n",
    "\n",
    "In this task we are going to build a LSA topic model from scratch. From lecture-04, we learned about LSA from the perspective of document retrieval. For document retrieval, you'll recall that we computed a truncated SVD by choosing some number of dimension $K << N$. This gave us the left singular column vectors, $\\mathbf{V} \\in \\mathbb{R}^{N \\times K}$, and the diagonal singular value matrix, $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{K \\times K}$ that we needed in order to project our queries, $\\mathbf{q} \\in \\mathbb{R}^{N}$, and documents, $\\mathbf{d} \\in \\mathbb{R}^{N}$, into $\\mathbb{R}^{K}$ space. Recall that the operation to do that was:\n",
    "\n",
    "$$\\hat{\\mathbf{q}} = \\mathbf{q}\\mathbf{V}\\mathbf{\\Sigma}^{-1} $$\n",
    "\n",
    "In this task, we're going to evaluate the singular values, $\\sigma_{i,j}$ in $\\mathbf{\\Sigma}$, and their corresponding basis vectors, $\\mathbf{u}^{(j)}$, in $\\mathbf{U}$, to extract the principal themes in the data. Execute the following subtasks.\n",
    "\n",
    "1. For each column vector, print out the top 10 most relevant words.\n",
    "2. Visualize the top 10 words using the `plot_topics()` function provided above.\n",
    "3. What affect does the hyperparameter $K$ have on the result?\n",
    "4. Is there a principled way to determine an appropriate value for $K$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192ef0ca-faf6-4703-ae8e-40b619ec2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c130a66-7c6e-42c0-b6c2-b7dee5ba993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3b782-5ced-480d-9abc-b88bc722747a",
   "metadata": {},
   "source": [
    "### (5 pts) Task 2: Perform topic extraction using the NMF and LDA models from sklearn\n",
    "\n",
    "In this task we perform topic extraction using the Non-negative Matrix Factorization (NMF) and Latent Dirichlet Allocation (LDA) models provided by sklearn. \n",
    "\n",
    "1. Fit the NMF and LDA models in the provided cells below.\n",
    "2. Visualize the results using the `plot_topics` function.\n",
    "3. How do the results compare to your home-spun LSA topic model?\n",
    "4. What are the differences between these model that might give rise to these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d62ac18-e738-47c8-86fc-2279bff226a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96020603-8e99-4993-95df-c8406ad65f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbbc47dd-0893-414b-8dc5-0a9d1ac0493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843fea2-8a3d-4760-a9f4-b17e4f2e1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f673115-7d0e-467b-93ee-7a32dc5c4e15",
   "metadata": {},
   "source": [
    "### (5 pts) Task 3: Map the test data onto the topic spaces learned from the LSA, NMF, and LDA models\n",
    "\n",
    "The purpose of this task is to assign topics to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c6a3d-3e8d-48bf-a598-7393aad8789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
