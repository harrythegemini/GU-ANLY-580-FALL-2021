{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514fffaf-36ee-4deb-802b-4685c2dcb1c6",
   "metadata": {},
   "source": [
    "# Lab-05: Visualizing tweets from the 2020 US presidential election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82dc807-629b-47e6-997d-c77bfb105cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset is a randomly sampled subset of: https://www.kaggle.com/manchunhui/us-election-2020-tweets\n",
    "trump = pd.read_csv(\"2020_tweets_trump.csv\", lineterminator='\\n')\n",
    "biden = pd.read_csv(\"2020_tweets_biden.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbac270-263e-4481-b7b6-a08aee76a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(biden), len(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5d88e-ae90-41cf-be32-00579cf35fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10000\n",
    "trump = trump.sample(n=M//2)\n",
    "biden = biden.sample(n=M//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50310e26-a410-42a1-81fb-be0b5ac32905",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets = biden['tweet'].tolist()\n",
    "trump_tweets = trump['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef537b0e-ca78-44af-bce3-0a9a21ba79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets[3023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3b36a-9598-4efb-b3ad-b0cccd331bb2",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a8f95-2929-404c-bc7e-695b617f883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "pipeline_name = '2020ElectionTweets'\n",
    "\n",
    "\n",
    "def camel_case_split(str):\n",
    "    \"\"\" This function turns in #Biden2020 into Biden 2020 \"\"\"\n",
    "    return \" \".join([wrd for wrd in re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', str)])\n",
    "\n",
    "\n",
    "@Language.component(pipeline_name)\n",
    "def preprocess(doc):\n",
    "    doc = [token for token in doc if not token.is_punct]\n",
    "    # doc = [token for token in doc if not token.is_stop]\n",
    "    doc = [token.text.lower().strip() for token in doc]\n",
    "    doc = [token for token in doc if 0 < len(token) <= 12]\n",
    "    return \" \".join(doc)\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    # http://emailregex.com/\n",
    "    email_re = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)\n",
    "    *|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]\n",
    "    |\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9]\n",
    "    (?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}\n",
    "    (?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:\n",
    "    (?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "    # replace = [ (pattern-to-replace, replacement),  ...]\n",
    "    replace = [\n",
    "        (\"<[^>]*>\", \" \"),\n",
    "        (email_re, \" \"),                           # Matches emails\n",
    "        (r\"(?<=\\d),(?=\\d)\", \"\"),                   # Remove commas in numbers\n",
    "        (r\"\\d+\", \" \"),                             # Map digits to special token <numbr>\n",
    "        (r\"[*\\^\\.$&@<>,\\-/+{|}=?#:;'\\\"\\[\\]]\", \"\"), # Punctuation and other junk\n",
    "        (r\"[\\n\\t\\r]\", \" \"),                        # Removes newlines, tabs, creturn\n",
    "        (r\"[^\\x00-\\x7F]+\", \"\"),                    # Removes non-ascii chars\n",
    "        (r\"\\\\+\", \" \"),                             # Removes double-backslashs\n",
    "        (r\"\\s+n\\s+\", \" \"),                         # 'n' leftover from \\\\n\n",
    "        (r\"\\s+\", \" \")                              # Strips extra whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = spacy.load('en_core_web_sm')\n",
    "        self.pipeline.add_pipe(pipeline_name);\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.transform(*args, **kwargs)\n",
    "\n",
    "    def transform(self, doc: str):\n",
    "        for repl in self.replace:\n",
    "            doc = re.sub(repl[0], repl[1], doc)\n",
    "        doc = camel_case_split(doc)\n",
    "        return self.pipeline(doc)\n",
    "    \n",
    "pipeline = Pipeline();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250385f-d94b-4110-ac61-6e4a638aa02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with tqdm(total=M//2) as bar:\n",
    "    for i, (bt, tt) in enumerate(zip(biden_tweets, trump_tweets)):\n",
    "        biden_tweets[i] = pipeline(bt)\n",
    "        trump_tweets[i] = pipeline(tt)\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafb08c-1348-4fca-bf4e-d304d67fcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets[3023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788113e-a737-4839-823d-5d385bb56b48",
   "metadata": {},
   "source": [
    "### Concatenate documents for vocab generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9ff05-9df9-4f51-91b4-f93a62e6d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = biden_tweets + trump_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95b19c-1577-434f-ab0d-6c13f07337cb",
   "metadata": {},
   "source": [
    "## (20 pts) Task I: Train a Doc2Vec model (using the Gensim package) on tweets from the 2020 US presidential election\n",
    "\n",
    "*Docs*: \n",
    "\n",
    "* https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "*Useful tutorials*: \n",
    "\n",
    "* https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial \n",
    "* https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43e854-6a1c-432d-a125-97e10849e49d",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cb3d6-26c8-455f-b5e6-7f6685ba8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change as needed\n",
    "K = 20\n",
    "word_frequency_threshold = 2\n",
    "epochs = 10\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e641c1-7e76-4e15-bd86-b79b4460adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec(vector_size=K, min_count=word_frequency_threshold, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad3f55-7428-4278-82e9-c7243f75498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb31c34-61b7-49b3-a31d-ad7c742a2876",
   "metadata": {},
   "source": [
    "## (10  pts) Task II: Evaluate your model by computing the most similar documents (tweets) to new (perhaps made up) tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2729a-a9ba-4daf-ab93-06936ebd16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template function\n",
    "def find_similar_tweets(tweet, top_n=10):\n",
    "    doc_vector = model.infer_vector(tweet)\n",
    "    sims = model.dv.most_similar([doc_vector], topn=top_n)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf0a8a-0b0c-447c-a619-96780f8a750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99900417-805a-415b-bbd4-ee456d1f9e5a",
   "metadata": {},
   "source": [
    "## (10 pts extra credit) Task III: Produce a scatter plot of the compressed document embeddings (2D or 3D)\n",
    "\n",
    "*Useful resources*:\n",
    "\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd360b-ea53-479f-bfbe-bc4f82268daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
